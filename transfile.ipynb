{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf4c70a-be44-4434-929d-e2c4a996bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deep_translator import GoogleTranslator\n",
    "import time\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba056ff9-5e56-441d-8458-2da0fd5aaaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created backup at input_backup.jsonl\n",
      "Translated 'VERIFIABLE' to 'قابل تصدیق'\n",
      "Translated 'NOT VERIFIABLE' to 'قابل تصدیق نہیں ہے'\n",
      "Translated 'NOT ENOUGH INFO' to 'کافی معلومات نہیں'\n",
      "Line 1: Claim: 'Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.' → 'نیکولج کوسٹر والڈاؤ نے فاکس براڈکاسٹنگ کمپنی کے ساتھ کام کیا۔'\n",
      "Verifiable: 'VERIFIABLE' → 'قابل تصدیق'\n",
      "Evidence translated (complex structure)\n",
      "Line 2: Claim: 'Roman Atwood is a content creator.' → 'رومن اتوڈ ایک مواد تخلیق کار ہے۔'\n",
      "Verifiable: 'VERIFIABLE' → 'قابل تصدیق'\n",
      "Evidence translated (complex structure)\n",
      "Line 3: Claim: 'History of art includes architecture, dance, sculpture, music, painting, poetry literature, theatre, narrative, film, photography and graphic arts.' → 'آرٹ کی تاریخ میں فن تعمیر ، رقص ، مجسمہ سازی ، موسیقی ، پینٹنگ ، شاعری ادب ، تھیٹر ، بیانیہ ، فلم ، فوٹو گرافی اور گرافک آرٹس شامل ہیں۔'\n",
      "Verifiable: 'VERIFIABLE' → 'قابل تصدیق'\n",
      "Evidence translated (complex structure)\n",
      "Line 4: Claim: 'Adrienne Bailon is an accountant.' → 'ایڈرین بیلن ایک اکاؤنٹنٹ ہیں۔'\n",
      "Verifiable: 'VERIFIABLE' → 'قابل تصدیق'\n",
      "Evidence translated (complex structure)\n",
      "Line 5: Claim: 'System of a Down briefly disbanded in limbo.' → 'ایک نیچے کا نظام مختصر طور پر لمبو میں منقطع ہوگیا۔'\n",
      "Verifiable: 'NOT VERIFIABLE' → 'قابل تصدیق نہیں ہے'\n",
      "Evidence translated (complex structure)\n",
      "Line 6: Claim: 'Homeland is an American television spy thriller based on the Israeli television series Prisoners of War.' → 'ہوم لینڈ ایک امریکی ٹیلی ویژن کے جاسوس تھرلر ہے جو اسرائیلی ٹیلی ویژن سیریز کے قیدیوں کے قیدیوں پر مبنی ہے۔'\n",
      "Verifiable: 'VERIFIABLE' → 'قابل تصدیق'\n",
      "Evidence translated (complex structure)\n",
      "Line 7: Claim: 'Beautiful reached number two on the Billboard Hot 100 in 2003.' → '2003 میں بل بورڈ ہاٹ 100 پر خوبصورت خوبصورت نمبر پر پہنچا۔'\n",
      "Verifiable: 'NOT VERIFIABLE' → 'قابل تصدیق نہیں ہے'\n",
      "Evidence translated (complex structure)\n",
      "Line 8: Claim: 'Neal Schon was named in 1954.' → 'نیل نے پہلے ہی 1954 میں نامزد کیا تھا۔'\n",
      "Verifiable: 'NOT VERIFIABLE' → 'قابل تصدیق نہیں ہے'\n",
      "Evidence translated (complex structure)\n",
      "Line 9: Claim: 'The Boston Celtics play their home games at TD Garden.' → 'بوسٹن سیلٹکس ٹی ڈی گارڈن میں اپنے گھریلو کھیل کھیلتے ہیں۔'\n",
      "Verifiable: 'VERIFIABLE' → 'قابل تصدیق'\n",
      "Evidence translated (complex structure)\n",
      "Line 10: Claim: 'The Ten Commandments is an epic film.' → 'دس احکام ایک مہاکاوی فلم ہے۔'\n",
      "Verifiable: 'VERIFIABLE' → 'قابل تصدیق'\n",
      "Evidence translated (complex structure)\n",
      "\n",
      "Translation completed!\n",
      "Total lines processed: 10\n",
      "Successfully translated: 10\n",
      "Errors/unchanged: 0\n",
      "Check translated2.jsonl for the translated data\n"
     ]
    }
   ],
   "source": [
    "# Initialize translator with Urdu as target language\n",
    "translator = GoogleTranslator(source='auto', target='ur')\n",
    "\n",
    "# Define file paths\n",
    "input_file = \"fever_chunk.jsonl\"\n",
    "output_file = \"translated2.jsonl\"\n",
    "backup_file = \"input_backup.jsonl\"\n",
    "\n",
    "# Create backup if doesn't exist\n",
    "if not os.path.exists(backup_file) and os.path.exists(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as src, open(backup_file, 'w', encoding='utf-8') as dst:\n",
    "        dst.write(src.read())\n",
    "    print(f\"Created backup at {backup_file}\")\n",
    "\n",
    "# Prepare translations for fixed values (verifiable field)\n",
    "verifiable_translations = {\n",
    "    \"VERIFIABLE\": None,\n",
    "    \"NOT VERIFIABLE\": None,\n",
    "    \"NOT ENOUGH INFO\": None\n",
    "}\n",
    "\n",
    "# Pre-translate these fixed values once\n",
    "for key in verifiable_translations.keys():\n",
    "    try:\n",
    "        verifiable_translations[key] = translator.translate(key)\n",
    "        print(f\"Translated '{key}' to '{verifiable_translations[key]}'\")\n",
    "        time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating '{key}': {e}\")\n",
    "        verifiable_translations[key] = key  # Fall back to original\n",
    "\n",
    "# Function to translate with retries and error handling\n",
    "def translate_with_retry(text, max_retries=3):\n",
    "    if not text or text == \"null\" or text is None:\n",
    "        return text\n",
    "        \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = translator.translate(text)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Translation error (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "            time.sleep(2)  # Wait before retry\n",
    "    \n",
    "    print(f\"Failed to translate after {max_retries} attempts: '{text}'\")\n",
    "    return text  # Return original text if all retries fail\n",
    "\n",
    "# Process evidence translation (which is a complex nested structure)\n",
    "def translate_evidence(evidence):\n",
    "    if not evidence or evidence == [[]] or evidence[0][0][1] is None:\n",
    "        return evidence\n",
    "        \n",
    "    # The structure is [[[id, id, article_name, sentence_id], ...], ...]\n",
    "    translated_evidence = []\n",
    "    \n",
    "    for evidence_group in evidence:\n",
    "        translated_group = []\n",
    "        for evidence_item in evidence_group:\n",
    "            # Only translate the article name (3rd element) if it's a string\n",
    "            if evidence_item and len(evidence_item) > 2 and evidence_item[2] is not None and isinstance(evidence_item[2], str):\n",
    "                # Extract article name and replace underscores with spaces for better translation\n",
    "                article_name = evidence_item[2].replace(\"_\", \" \")\n",
    "                article_name = re.sub(r'-LRB-', '(', article_name)\n",
    "                article_name = re.sub(r'-RRB-', ')', article_name)\n",
    "                \n",
    "                # Translate and convert back to wiki format\n",
    "                translated_name = translate_with_retry(article_name)\n",
    "                if translated_name != article_name:  # Only replace if translation succeeded\n",
    "                    evidence_item = evidence_item.copy()  # Create a copy to avoid modifying the original\n",
    "                    evidence_item[2] = translated_name\n",
    "                \n",
    "            translated_group.append(evidence_item)\n",
    "        \n",
    "        translated_evidence.append(translated_group)\n",
    "    \n",
    "    return translated_evidence\n",
    "\n",
    "# Open input and output files\n",
    "line_count = 0\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "try:\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            line_count += 1\n",
    "            try:\n",
    "                # Parse the JSON line\n",
    "                data = json.loads(line.strip())\n",
    "                modified = False\n",
    "                \n",
    "                # Translate the claim field\n",
    "                if \"claim\" in data and data[\"claim\"]:\n",
    "                    original_claim = data[\"claim\"]\n",
    "                    data[\"claim\"] = translate_with_retry(original_claim)\n",
    "                    print(f\"Line {line_num}: Claim: '{original_claim}' → '{data['claim']}'\")\n",
    "                    if data[\"claim\"] != original_claim:\n",
    "                        modified = True\n",
    "                \n",
    "                # Translate the verifiable field (using our pre-translated values)\n",
    "                if \"verifiable\" in data and data[\"verifiable\"]:\n",
    "                    original_verifiable = data[\"verifiable\"]\n",
    "                    if original_verifiable in verifiable_translations:\n",
    "                        data[\"verifiable\"] = verifiable_translations[original_verifiable]\n",
    "                        print(f\"Verifiable: '{original_verifiable}' → '{data['verifiable']}'\")\n",
    "                        if data[\"verifiable\"] != original_verifiable:\n",
    "                            modified = True\n",
    "                \n",
    "                # Translate the evidence field (which is complex)\n",
    "                if \"evidence\" in data and data[\"evidence\"]:\n",
    "                    original_evidence = data[\"evidence\"]\n",
    "                    data[\"evidence\"] = translate_evidence(original_evidence)\n",
    "                    print(f\"Evidence translated (complex structure)\")\n",
    "                    if data[\"evidence\"] != original_evidence:\n",
    "                        modified = True\n",
    "                \n",
    "                # Track success/failure\n",
    "                if modified:\n",
    "                    success_count += 1\n",
    "                else:\n",
    "                    print(f\"  WARNING: No fields were modified in line {line_num}\")\n",
    "                    error_count += 1\n",
    "                \n",
    "                # Write the modified JSON object back\n",
    "                outfile.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "                \n",
    "                # Add a small delay to avoid rate limiting\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error: Line {line_num} is not valid JSON. Copying original line.\")\n",
    "                outfile.write(line)\n",
    "                error_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error on line {line_num}: {e}. Copying original line.\")\n",
    "                outfile.write(line)\n",
    "                error_count += 1\n",
    "                \n",
    "    print(f\"\\nTranslation completed!\")\n",
    "    print(f\"Total lines processed: {line_count}\")\n",
    "    print(f\"Successfully translated: {success_count}\")\n",
    "    print(f\"Errors/unchanged: {error_count}\")\n",
    "    print(f\"Check {output_file} for the translated data\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find the input file '{input_file}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ff0f2-7793-4861-9ada-4b9754b988ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
